{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "td_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "RvVSCm38ndRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "ee7c8418-efae-4eb7-cdbd-677559f15f34"
      },
      "cell_type": "code",
      "source": [
        "# @title Install Dependencies\n",
        "!pip install numpy\n",
        "!pip install gym"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Collecting gym\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/44/3a63e8b87f642db49ac81239620e68df8cfae223dcfda4f8508aec88d204/gym-0.10.8.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.6)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Collecting pyglet>=1.2.0 (from gym)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.0MB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.8.24)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Running setup.py bdist_wheel for gym ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ea/ec/dd/33bcc8801d345f0b640fced8a0864a7c8474828564bc5ccf70\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, gym\n",
            "Successfully installed gym-0.10.8 pyglet-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dCK4N8w2njkj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# @title Import required libraries\n",
        "import numpy as np\n",
        "import gym"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jym2is8MnEf9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# @title TD(0) prediction method\n",
        "EPSILON = 0.1\n",
        "GAMMA = 1.0\n",
        "ALPHA = 0.2\n",
        "N_EPISODES = 10000\n",
        "\n",
        "def generate_rand_policy(env):\n",
        "  policy = []\n",
        "  for i in range(env.env.nS):\n",
        "    policy.append(env.action_space.sample())\n",
        "  return policy\n",
        "\n",
        "def eps_greedy_policy(state, policy, epsilon=EPSILON):\n",
        "  prob = np.random.random()\n",
        "  if prob < (1 - epsilon):\n",
        "    return policy[state]\n",
        "  else:\n",
        "    return env.action_space.sample()\n",
        "\n",
        "def td_0(env, alpha=ALPHA, epsilon=EPSILON, gamma=GAMMA, num_episodes=N_EPISODES):\n",
        "  V = np.zeros(env.env.nS)\n",
        "  wins = 0\n",
        "  policy = generate_rand_policy(env)\n",
        "  for i_episode in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    timesteps = 0\n",
        "    while True:\n",
        "      action = eps_greedy_policy(state, policy)\n",
        "      next_state, reward, done, _ = env.step(action)\n",
        "      V[state] = V[state] + alpha*(reward + gamma*V[next_state] - V[state])\n",
        "      if done:\n",
        "        if next_state == 15:\n",
        "          wins += 1\n",
        "        break\n",
        "      state = next_state\n",
        "      timesteps += 1\n",
        "  return V, wins\n",
        "\n",
        "def sarsa(env, num_episodes=N_EPISODES, alpha=ALPHA, epsilon=EPSILON, gamma=GAMMA):\n",
        "  Q = np.zeros((env.env.nS, env.env.nA))\n",
        "  policy = generate_rand_policy(env)\n",
        "  wins = 0\n",
        "  for i_episode in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    action = eps_greedy_policy(state, policy)\n",
        "    while True:\n",
        "      next_state, reward, done, _ = env.step(action)\n",
        "      next_action = eps_greedy_policy(next_state, policy)\n",
        "      Q[state][action] = Q[state][action] + \\\n",
        "        alpha*(reward + gamma*Q[next_state][next_action] - Q[state][action])\n",
        "      state = next_state\n",
        "      action = next_action\n",
        "      policy[state] = np.argmax(Q[state])\n",
        "      if done:\n",
        "        if state == 15:\n",
        "          wins += 1\n",
        "        break\n",
        "  return wins\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4usoJQK5zc9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "f67913e0-0b09-4720-d31b-ea1cc80bb368"
      },
      "cell_type": "code",
      "source": [
        "# @title Shows TD(0) Agent's success\n",
        "env = gym.make('FrozenLake-v0')\n",
        "for _ in range(50):\n",
        "  _, wins = td_0(env)\n",
        "  print(\"Agent wins {} games of {} games\".format(wins, N_EPISODES))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Agent wins 69 games of 10000 games\n",
            "Agent wins 66 games of 10000 games\n",
            "Agent wins 458 games of 10000 games\n",
            "Agent wins 121 games of 10000 games\n",
            "Agent wins 53 games of 10000 games\n",
            "Agent wins 515 games of 10000 games\n",
            "Agent wins 26 games of 10000 games\n",
            "Agent wins 185 games of 10000 games\n",
            "Agent wins 184 games of 10000 games\n",
            "Agent wins 37 games of 10000 games\n",
            "Agent wins 7 games of 10000 games\n",
            "Agent wins 130 games of 10000 games\n",
            "Agent wins 77 games of 10000 games\n",
            "Agent wins 285 games of 10000 games\n",
            "Agent wins 759 games of 10000 games\n",
            "Agent wins 34 games of 10000 games\n",
            "Agent wins 368 games of 10000 games\n",
            "Agent wins 153 games of 10000 games\n",
            "Agent wins 94 games of 10000 games\n",
            "Agent wins 377 games of 10000 games\n",
            "Agent wins 329 games of 10000 games\n",
            "Agent wins 64 games of 10000 games\n",
            "Agent wins 133 games of 10000 games\n",
            "Agent wins 286 games of 10000 games\n",
            "Agent wins 69 games of 10000 games\n",
            "Agent wins 28 games of 10000 games\n",
            "Agent wins 5 games of 10000 games\n",
            "Agent wins 139 games of 10000 games\n",
            "Agent wins 29 games of 10000 games\n",
            "Agent wins 37 games of 10000 games\n",
            "Agent wins 39 games of 10000 games\n",
            "Agent wins 115 games of 10000 games\n",
            "Agent wins 73 games of 10000 games\n",
            "Agent wins 185 games of 10000 games\n",
            "Agent wins 294 games of 10000 games\n",
            "Agent wins 33 games of 10000 games\n",
            "Agent wins 227 games of 10000 games\n",
            "Agent wins 260 games of 10000 games\n",
            "Agent wins 56 games of 10000 games\n",
            "Agent wins 72 games of 10000 games\n",
            "Agent wins 49 games of 10000 games\n",
            "Agent wins 85 games of 10000 games\n",
            "Agent wins 28 games of 10000 games\n",
            "Agent wins 16 games of 10000 games\n",
            "Agent wins 546 games of 10000 games\n",
            "Agent wins 38 games of 10000 games\n",
            "Agent wins 8 games of 10000 games\n",
            "Agent wins 567 games of 10000 games\n",
            "Agent wins 339 games of 10000 games\n",
            "Agent wins 157 games of 10000 games\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7ZqTRj9OOJFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "691993e1-feac-4c06-a3c8-cbb5ee55adc4"
      },
      "cell_type": "code",
      "source": [
        "# @title Shows SARSA Agent's success\n",
        "env = gym.make('FrozenLake-v0')\n",
        "N_SES = 10\n",
        "sum = 0\n",
        "success = 0\n",
        "policy = generate_rand_policy(env)\n",
        "for _ in range(N_SES):\n",
        "  wins = sarsa(env)\n",
        "  if wins > success:\n",
        "    success = wins\n",
        "  sum += wins\n",
        "mean = sum/N_SES\n",
        "print(\"The mean wins of the agent are {} of {} games after {} learning sessions\".format(mean, N_EPISODES, N_SES))\n",
        "print(\"The best result of the agent was {} wins of {} games after {} learning sessions\".format(success, N_EPISODES, N_SES))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean wins of the agent are 1668.4 of 10000 games after 10 learning sessions\n",
            "The best result of the agent was 3019 wins of 10000 games after 10 learning sessions\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
