{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_mnist_torch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "K1sQ0J4PzfgV"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarkGengar/100DaysOfMLCode/blob/master/cnn_mnist_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "K1sQ0J4PzfgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Installation Setup for Cuda 9.2 and Pytorch**"
      ]
    },
    {
      "metadata": {
        "id": "509PvTw2sPde",
        "colab_type": "code",
        "outputId": "6c648c66-f340-48c6-8b3c-9183e2cb8d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "!cat /etc/*-release"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DISTRIB_ID=Ubuntu\n",
            "DISTRIB_RELEASE=18.04\n",
            "DISTRIB_CODENAME=bionic\n",
            "DISTRIB_DESCRIPTION=\"Ubuntu 18.04.1 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.1 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.1 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gHTjfIzytHDU",
        "colab_type": "code",
        "outputId": "89bb0f11-9301-4818-be1f-fbc96a445cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "# NVIDIA profiling tool for the available GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Dec  4 21:46:46 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "61t0XqQotR-j",
        "colab_type": "code",
        "outputId": "463cbf3e-5b31-402a-effb-6343dd35276f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# CLone my repo that contains the shell file\n",
        "!git clone https://gist.github.com/f7b7c7758a46da49f84bc68b47997d69.git"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'f7b7c7758a46da49f84bc68b47997d69' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZZ6gwL40tS1B",
        "colab_type": "code",
        "outputId": "170b4f71-6835-4814-d9f9-c48f3870b83d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Move to te directory where the file was donwloaded\n",
        "cd f7b7c7758a46da49f84bc68b47997d69/"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/f7b7c7758a46da49f84bc68b47997d69/f7b7c7758a46da49f84bc68b47997d69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2y1pdHYWtVum",
        "colab_type": "code",
        "outputId": "c86ca42f-cfd9-42c0-fa10-bd81a9987a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod2/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-04 21:46:49--  https://developer.nvidia.com/compute/cuda/9.2/Prod2/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64\n",
            "Resolving developer.nvidia.com (developer.nvidia.com)... 192.229.162.216\n",
            "Connecting to developer.nvidia.com (developer.nvidia.com)|192.229.162.216|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://developer.download.nvidia.com/compute/cuda/9.2/secure/Prod2/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64.deb?MbNPGxnIlDyM9OrHH8T_PoOkf8wU9TRcKS5s1UhvInRpaSOsi-dZYyxuZZxOSKRUSd3FITQ5RHXTnptBw3Tbw-1UCpHuw_FwJ2-VLdaNv1iTfkiE15dRAIwAKQy3qjD50A5W1JKMBifVECCxE_HEkTke3fYXDeRJY5zVx0BR5WShn9mr-uHC08ks5iTaxW1-opdqi4sWQvOo1smgTLie6Q [following]\n",
            "--2018-12-04 21:46:50--  https://developer.download.nvidia.com/compute/cuda/9.2/secure/Prod2/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64.deb?MbNPGxnIlDyM9OrHH8T_PoOkf8wU9TRcKS5s1UhvInRpaSOsi-dZYyxuZZxOSKRUSd3FITQ5RHXTnptBw3Tbw-1UCpHuw_FwJ2-VLdaNv1iTfkiE15dRAIwAKQy3qjD50A5W1JKMBifVECCxE_HEkTke3fYXDeRJY5zVx0BR5WShn9mr-uHC08ks5iTaxW1-opdqi4sWQvOo1smgTLie6Q\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.211.70, 2606:2800:21f:3aa:dcf:37b:1ed6:1fb\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.211.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1267151038 (1.2G) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64.1’\n",
            "\n",
            "cuda-repo-ubuntu160 100%[===================>]   1.18G   115MB/s    in 9.6s    \n",
            "\n",
            "2018-12-04 21:47:00 (126 MB/s) - ‘cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64.1’ saved [1267151038/1267151038]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Km4B923ItrP0",
        "colab_type": "code",
        "outputId": "c3bc3706-2c4f-4b1f-d5ef-b29b483261cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "!dpkg --install cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 82932 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64 ...\n",
            "Unpacking cuda-repo-ubuntu1604-9-2-local (9.2.148-1) over (9.2.148-1) ...\n",
            "Setting up cuda-repo-ubuntu1604-9-2-local (9.2.148-1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ndWPW7BXtuGR",
        "colab_type": "code",
        "outputId": "5e787aed-eedf-4fb4-887a-a286bbe3a84f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4OtPwhhKtxsy",
        "colab_type": "code",
        "outputId": "b2006138-1a09-4c22-c117-9f0e241c74f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 file:/var/cuda-repo-9-2-local  InRelease\n",
            "\r            \rIgn:1 file:/var/cuda-repo-9-2-local  InRelease\n",
            "\r0% [Connecting to security.ubuntu.com] [Connecting to ppa.launchpad.net]\r                                                                        \rGet:2 file:/var/cuda-repo-9-2-local  Release [574 B]\n",
            "\r0% [Connecting to security.ubuntu.com] [Connecting to developer.download.nvidia\r                                                                               \rGet:2 file:/var/cuda-repo-9-2-local  Release [574 B]\n",
            "\r0% [2 Release 0 B/574 B 0%] [Connecting to archive.ubuntu.com] [Connecting to s\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r0% [Release.gpg gpgv 574 B] [Connecting to archive.ubuntu.com] [Connecting to s\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [83.2 kB]\n",
            "\r0% [Release.gpg gpgv 574 B] [Connecting to archive.ubuntu.com (91.189.88.152)] \r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  InRelease\n",
            "\r0% [Release.gpg gpgv 574 B] [Waiting for headers] [3 InRelease 48.9 kB/83.2 kB \r0% [Release.gpg gpgv 574 B] [Waiting for headers] [Waiting for headers] [Waitin\r                                                                               \rHit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r                                                                               \r0% [Release.gpg gpgv 574 B] [Waiting for headers] [Waiting for headers]\r                                                                       \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\n",
            "\r                                                                       \r0% [Release.gpg gpgv 574 B] [Waiting for headers]\r                                                 \rHit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  Release\n",
            "\r0% [Release.gpg gpgv 574 B] [Waiting for headers]\r                                                 \rHit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [745 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [585 kB]\n",
            "Fetched 1,576 kB in 2s (656 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QLHm02Plt1dA",
        "colab_type": "code",
        "outputId": "24e057cf-34e1-4c60-c0c1-57ad0581a61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "# NOTE: This might take some time..\n",
        "!apt-get install cuda"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda is already the newest version (9.2.148-1).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " cuda-drivers : Depends: nvidia-396 (>= 396.44) but it is not going to be installed\n",
            " libcuda1-396 : Depends: nvidia-396 (>= 396.44) but it is not going to be installed\n",
            " nvidia-396-dev : Depends: nvidia-396 (>= 396.44) but it is not going to be installed\n",
            " nvidia-opencl-icd-396 : Depends: nvidia-396 (>= 396.44) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ps23ZBAxt-Ax",
        "colab_type": "code",
        "outputId": "6f137a7e-4580-472e-dbf3-64216733f3ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Check the version of CUDA on the system\n",
        "!cat /usr/local/cuda/version.txt"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Version 9.2.148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fcghEe3buCCY",
        "colab_type": "code",
        "outputId": "172c7099-5611-4ff9-acb9-8e827943af71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.1 from http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DLMWid3juGFR",
        "colab_type": "code",
        "outputId": "69478296-63f6-4f53-98fb-627759751bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PFzNWDoQuG1o",
        "colab_type": "code",
        "outputId": "4f0cc187-de0b-4a6e-c37d-d0bed6192558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# Use PyTorch to check versions, CUDA version and cuDNN\n",
        "\n",
        "import torch\n",
        "\n",
        "print(\"PyTorch version: \")\n",
        "print(torch.__version__)\n",
        "print(\"CUDA Version: \")\n",
        "print(torch.version.cuda)\n",
        "print(\"cuDNN version is: \")\n",
        "print(torch.backends.cudnn.version())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version: \n",
            "0.4.1\n",
            "CUDA Version: \n",
            "9.2.148\n",
            "cuDNN version is: \n",
            "7104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pqDDHrmLt0kk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##**Setup Google Colab for data reading and uploading from or to Google Drive**"
      ]
    },
    {
      "metadata": {
        "id": "S5wMlreDuC30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "axA_mWRck2il",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iDVa_BeH3Kh6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Upload model\n",
        "# If update True update existing model\n",
        "# else create a new GoogleDriveFile instance\n",
        "# If you have not upload a model so far set update=False\n",
        "# TODO: consistence of dest_dir_id and model_file\n",
        "def upload_model_to_gd(dest_dir_id, model_file, src_file, update=False):\n",
        "  uploaded = None\n",
        "  if update:\n",
        "    file_list = drive.ListFile({'q': dest_dir_id + \" in parents and title=\" + model_file + \" and trashed=false\"}).GetList()\n",
        "    if len(file_list) == 1:\n",
        "      uploaded = drive.CreateFile({'id' : file_list[0]['id']})\n",
        "    else:\n",
        "      print('In the directory are multiple files with the same name.')\n",
        "  else:\n",
        "    uploaded = drive.CreateFile({'title': 'model.h5', 'parents': [{'kind': 'drive#fileLink','id': dest_dir_id}]})\n",
        "  uploaded.SetContentFile(src_file)\n",
        "  uploaded.Upload()\n",
        "  print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "  \n",
        "def load_model_from_gd(model_id, dest_file):\n",
        "  # Create GoogleDriveFile instance\n",
        "  downloaded = drive.CreateFile({'id': model_id})\n",
        "  # Load content of downloaded file in 'OUTPUT_FILE'\n",
        "  downloaded.GetContentFile(dest_file)\n",
        "  model = torch.load(dest_file)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kmUmf3weUkrx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##**Convolutional Neural Network**\n",
        "**Best Accuracy of the Network:** 98.35 % \\\n",
        "**Parameters:** \\\n",
        "Kernel"
      ]
    },
    {
      "metadata": {
        "id": "KjA_YwMeUrlC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GJpg3NmHVNDQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Load MNIST Dataset\n",
        "transform = transforms.Compose(\n",
        "  [transforms.ToTensor(),\n",
        "   transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                      download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                     download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fdz0tI4FXNSh",
        "colab_type": "code",
        "outputId": "9dd6813a-6758-4401-8480-f6a25f9f7d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "  img = img / 2 + 0.5\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "  \n",
        "dataiter = iter(trainloader)\n",
        "data = dataiter.next()\n",
        "images, _ = data\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAACUCAYAAADS6CNDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTva/CcMLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb897a1a358>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Ng5TmWt8YVgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 5, kernel_size=5)\n",
        "    self.pool = nn.MaxPool2d((2,2))\n",
        "    self.conv2 = nn.Conv2d(5, 5, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(5 * 10 * 10, 100)\n",
        "    self.fc2 = nn.Linear(100, 60)\n",
        "    self.fc3 = nn.Linear(60, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 5 * 10 * 10)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "  \n",
        "  def train(self, epochs=8):\n",
        "    for epoch in range(epochs):\n",
        "      for data in trainloader:\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      #save_model(self)\n",
        "    print('Finished Training')\n",
        "    \n",
        "  def query(self):\n",
        "    total = 0\n",
        "    score = 0\n",
        "    with torch.no_grad():\n",
        "      for data in testloader:\n",
        "        inputs, labels = data\n",
        "        outputs = model(inputs)\n",
        "        _, prediction = torch.max(outputs, 1)\n",
        "        total += labels.shape[0]\n",
        "        score += (prediction==labels).sum().item()\n",
        "      print('Accuracy of Neural Network on the {} test images: {} %'.format(total, score/total * 100))\n",
        "  \n",
        "def save_model(model):\n",
        "  torch.save(model, 'cnn_mnist_torch.pt')\n",
        "    \n",
        "def load_model():\n",
        "  if os.path.isfile('cnn_mnist_torch.pt'):\n",
        "    model = torch.load('cnn_mnist_torch.pt')\n",
        "    return model\n",
        "  else:\n",
        "    print(\"Model not found.\")\n",
        "    return None\n",
        "model = LeNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Owf04AsBbYAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fd28e6f-4c24-41d5-8e18-6020092455cf"
      },
      "cell_type": "code",
      "source": [
        "#@title Create Directory for downloaded file\n",
        "# Local path in Google Colab\n",
        "DOWNLOAD_PATH = os.path.expanduser('~/data')\n",
        "# Local file in Google colab\n",
        "DOWNLOAD_FILE = 'tmp_model.h5'\n",
        "OUTPUT_FILE = os.path.join(DOWNLOAD_PATH, DOWNLOAD_FILE)\n",
        "\n",
        "try:\n",
        "  os.makedirs(DOWNLOAD_PATH)\n",
        "except FileExistsError:\n",
        "  print('The Directory path already exist.')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Directory path already exist.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "auDhmydhpR2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "05cc8273-9c7a-4439-e222-2fe5608b24a3"
      },
      "cell_type": "code",
      "source": [
        "#@title Load model from Google Drive\n",
        "# ID of model file of Google Drive\n",
        "MODEL_ID = '1fNNLsNDDDR3AVFoTcPRP4X9hptseFSvI'\n",
        "model = load_model_from_gd(MODEL_ID, OUTPUT_FILE)\n",
        "print(model)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 5, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(5, 5, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=500, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=60, bias=True)\n",
            "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "94KzuYwRk7N4",
        "colab_type": "code",
        "outputId": "a454b98f-e240-4fbd-9c1b-3c4d8db196f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1050
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Upload model to Google Drive\n",
        "DEST_DIR_ID = \"'1fRs6PMtvJQmFOSLP-tifK_YEAFvB93Fq'\"\n",
        "# ID of destination folder of Google Drive\n",
        "GD_FOLDER_ID = '1fRs6PMtvJQmFOSLP-tifK_YEAFvB93Fq'\n",
        "# Name of destination file of Google Drive\n",
        "GD_FILE = \"'model.h5'\"\n",
        "upload_model_to_gd(DEST_DIR_ID, GD_FILE, OUTPUT_FILE, update=True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HttpError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-4690b1088262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Name of destination file of Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mGD_FILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mupload_model_to_gd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEST_DIR_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGD_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-184b9ced7281>\u001b[0m in \u001b[0;36mupload_model_to_gd\u001b[0;34m(dest_dir_id, model_file, src_file, update)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdest_dir_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" in parents and title=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_file\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" and trashed=false\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/apiattr.py\u001b[0m in \u001b[0;36mGetList\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maxResults'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maxResults'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/apiattr.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'pageToken'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pageToken'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_GetList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pageToken'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nextPageToken'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/auth.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGet_Http_Object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36m_GetList\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \"\"\"\n\u001b[1;32m     63\u001b[0m     self.metadata = self.auth.service.files().list(**dict(self)).execute(\n\u001b[0;32m---> 64\u001b[0;31m       http=self.http)\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_metadata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://www.googleapis.com/drive/v2/files?q=%271fRs6PMtvJQmFOSLP-tifK_YEAFvB93Fq%27+in+parents+and+title%3Dmodel.h5+and+trashed%3Dfalse&maxResults=1000&alt=json returned \"Invalid query\">"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xK5u7oI6oNoB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uytkXlocosLM",
        "colab_type": "code",
        "outputId": "5590970e-e8af-4a59-94c0-1622c707f217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.train(epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "usYHNx-9s1-J",
        "colab_type": "code",
        "outputId": "636a1d47-46fd-4ae5-a283-63b6a2b3504f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.query()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Neural Network on the 10000 test images: 98.24000000000001 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xP97F9_JQvzM",
        "colab_type": "code",
        "outputId": "dc58019d-10c3-4d23-e8f8-003ff09bd233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "torch.save(model, OUTPUT_FILE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type LeNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}