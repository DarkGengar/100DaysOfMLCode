{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_mnist_torch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "K1sQ0J4PzfgV",
        "pqDDHrmLt0kk",
        "kmUmf3weUkrx"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarkGengar/100DaysOfMLCode/blob/master/cnn_mnist_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "K1sQ0J4PzfgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Installation Setup for Cuda 9.2 and Pytorch**"
      ]
    },
    {
      "metadata": {
        "id": "509PvTw2sPde",
        "colab_type": "code",
        "outputId": "ea1896c5-17d3-4c19-fc30-f6c32d9ef6fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "!cat /etc/*-release"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DISTRIB_ID=Ubuntu\n",
            "DISTRIB_RELEASE=18.04\n",
            "DISTRIB_CODENAME=bionic\n",
            "DISTRIB_DESCRIPTION=\"Ubuntu 18.04.1 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.1 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.1 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gHTjfIzytHDU",
        "colab_type": "code",
        "outputId": "4fe6816a-3290-46ba-f150-961b2b6c3c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "# NVIDIA profiling tool for the available GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Dec  3 20:23:04 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    29W / 149W |     11MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "61t0XqQotR-j",
        "colab_type": "code",
        "outputId": "840261de-b2c7-4830-b32d-d8ec73cc5217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# CLone my repo that contains the shell file\n",
        "!git clone https://gist.github.com/f7b7c7758a46da49f84bc68b47997d69.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'f7b7c7758a46da49f84bc68b47997d69'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Total 16 (delta 0), reused 0 (delta 0), pack-reused 16\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZZ6gwL40tS1B",
        "colab_type": "code",
        "outputId": "c42996f7-4e2d-4f32-919e-ec49a1e34e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Move to te directory where the file was donwloaded\n",
        "cd f7b7c7758a46da49f84bc68b47997d69/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/f7b7c7758a46da49f84bc68b47997d69/f7b7c7758a46da49f84bc68b47997d69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2y1pdHYWtVum",
        "colab_type": "code",
        "outputId": "482876c5-0c61-49f2-d54c-69eb998440c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod2/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-03 20:23:10--  https://developer.nvidia.com/compute/cuda/9.2/Prod2/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64\n",
            "Resolving developer.nvidia.com (developer.nvidia.com)... 192.229.182.215\n",
            "Connecting to developer.nvidia.com (developer.nvidia.com)|192.229.182.215|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://developer.download.nvidia.com/compute/cuda/9.2/secure/Prod2/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64.deb?6CnRKVeY4XCBja9zUvk-duVbcER0XXao1aDizelmTbNWyOJgs7cQLbYB2TJm6Tbv7i5G6cUOXBRuW35lJ2Y-26xJXU4JEJCyXGT-ALxLqIG8FHq6M_RsO4MoqOF7cZphdkizZ8OwkR5Sv1mgUtqFpnBFRdhKBMZ5KFJXZlJGoDX5Risp3tC87f9u3JJ5MmDhEsHa6HXqAaHvuhGtRFJ7iA [following]\n",
            "--2018-12-03 20:23:11--  https://developer.download.nvidia.com/compute/cuda/9.2/secure/Prod2/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64.deb?6CnRKVeY4XCBja9zUvk-duVbcER0XXao1aDizelmTbNWyOJgs7cQLbYB2TJm6Tbv7i5G6cUOXBRuW35lJ2Y-26xJXU4JEJCyXGT-ALxLqIG8FHq6M_RsO4MoqOF7cZphdkizZ8OwkR5Sv1mgUtqFpnBFRdhKBMZ5KFJXZlJGoDX5Risp3tC87f9u3JJ5MmDhEsHa6HXqAaHvuhGtRFJ7iA\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.221.58, 2606:2800:233:ef6:15dd:1ece:1d50:1e1\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.221.58|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1267151038 (1.2G) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64’\n",
            "\n",
            "cuda-repo-ubuntu160 100%[===================>]   1.18G  93.8MB/s    in 14s     \n",
            "\n",
            "2018-12-03 20:23:25 (84.4 MB/s) - ‘cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64’ saved [1267151038/1267151038]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Km4B923ItrP0",
        "colab_type": "code",
        "outputId": "8d20fb37-c07d-451c-bf35-cdf697da10cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!dpkg --install cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 82932 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64 ...\n",
            "Unpacking cuda-repo-ubuntu1604-9-2-local (9.2.148-1) over (9.2.148-1) ...\n",
            "Setting up cuda-repo-ubuntu1604-9-2-local (9.2.148-1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ndWPW7BXtuGR",
        "colab_type": "code",
        "outputId": "36f5c8e6-8016-4649-f733-42f398502698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4OtPwhhKtxsy",
        "colab_type": "code",
        "outputId": "64bc0a21-6fd6-42ed-f8f4-a04606bfbff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 file:/var/cuda-repo-9-2-local  InRelease\n",
            "\r0% [1 InRelease 0 B] [Connecting to ppa.launchpad.net]\r                                                      \rIgn:1 file:/var/cuda-repo-9-2-local  InRelease\n",
            "\r                                                      \r0% [Connecting to ppa.launchpad.net (91.189.95.83)]\r                                                   \rGet:2 file:/var/cuda-repo-9-2-local  Release [574 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r                                                                               \rGet:2 file:/var/cuda-repo-9-2-local  Release [574 B]\n",
            "\r0% [2 Release 0 B/574 B 0%] [Waiting for headers] [Connecting to security.ubunt\r                                                                               \rHit:3 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [2 Release 574 B/574 B 100%] [Waiting for headers] [Connecting to security.u\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.23)] [Co\r0% [3 InRelease gpgv 21.3 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rGet:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [3 InRelease gpgv 21.3 kB] [5 InRelease 2,604 B/88.7 kB 3%] [Connecting to s\r0% [3 InRelease gpgv 21.3 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [83.2 kB]\n",
            "Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [580 kB]\n",
            "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  Release\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [744 kB]\n",
            "Fetched 1,570 kB in 2s (983 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QLHm02Plt1dA",
        "colab_type": "code",
        "outputId": "fd371536-0028-4a86-8cc7-7d022c06b499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# NOTE: This might take some time..\n",
        "!apt-get install cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda is already the newest version (9.2.148-1).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " cuda-drivers : Depends: nvidia-396 (>= 396.44) but it is not going to be installed\n",
            " libcuda1-396 : Depends: nvidia-396 (>= 396.44) but it is not going to be installed\n",
            " nvidia-396-dev : Depends: nvidia-396 (>= 396.44) but it is not going to be installed\n",
            " nvidia-opencl-icd-396 : Depends: nvidia-396 (>= 396.44) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ps23ZBAxt-Ax",
        "colab_type": "code",
        "outputId": "b2fe54df-5891-455d-8f84-de18a3548071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Check the version of CUDA on the system\n",
        "!cat /usr/local/cuda/version.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Version 9.2.148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fcghEe3buCCY",
        "colab_type": "code",
        "outputId": "b2362e50-9efd-445b-f6ca-25dd51726369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.1 from http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DLMWid3juGFR",
        "colab_type": "code",
        "outputId": "dfd7fa3b-4b8e-41b6-d8f6-b7e8b1f7f941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PFzNWDoQuG1o",
        "colab_type": "code",
        "outputId": "7df5eed8-6e5b-430e-ad42-7ce96d892915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "# Use PyTorch to check versions, CUDA version and cuDNN\n",
        "\n",
        "import torch\n",
        "\n",
        "print(\"PyTorch version: \")\n",
        "print(torch.__version__)\n",
        "print(\"CUDA Version: \")\n",
        "print(torch.version.cuda)\n",
        "print(\"cuDNN version is: \")\n",
        "print(torch.backends.cudnn.version())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version: \n",
            "0.4.1\n",
            "CUDA Version: \n",
            "9.2.148\n",
            "cuDNN version is: \n",
            "7104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pqDDHrmLt0kk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##**Setup Google Colab for data reading and uploading from or to Google Drive**"
      ]
    },
    {
      "metadata": {
        "id": "S5wMlreDuC30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "axA_mWRck2il",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kmUmf3weUkrx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##**Convolutional Neural Network**\n",
        "**Best Accuracy of the Network:** 98.35 % \\\n",
        "**Parameters:** \\\n",
        "Kernel"
      ]
    },
    {
      "metadata": {
        "id": "KjA_YwMeUrlC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GJpg3NmHVNDQ",
        "colab_type": "code",
        "outputId": "639c60ef-8c27-4ff0-f87b-602e559a7be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Load MNIST Dataset\n",
        "transform = transforms.Compose(\n",
        "  [transforms.ToTensor(),\n",
        "   transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                      download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                     download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fdz0tI4FXNSh",
        "colab_type": "code",
        "outputId": "5fd83aad-4ac4-4b57-9cbb-73bb2f7099c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "  img = img / 2 + 0.5\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "  \n",
        "dataiter = iter(trainloader)\n",
        "data = dataiter.next()\n",
        "images, _ = data\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAACUCAYAAADS6CNDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\na4wxxnjMLr7GGGOMx/4PgSnYMylLIngAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f245b5bc860>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Ng5TmWt8YVgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 5, kernel_size=5)\n",
        "    self.pool = nn.MaxPool2d((2,2))\n",
        "    self.conv2 = nn.Conv2d(5, 5, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(5 * 10 * 10, 100)\n",
        "    self.fc2 = nn.Linear(100, 60)\n",
        "    self.fc3 = nn.Linear(60, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 5 * 10 * 10)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "  \n",
        "  def train(self, epochs=8):\n",
        "    for epoch in range(epochs):\n",
        "      for data in trainloader:\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      #save_model(self)\n",
        "    print('Finished Training')\n",
        "    \n",
        "  def query(self):\n",
        "    total = 0\n",
        "    score = 0\n",
        "    with torch.no_grad():\n",
        "      for data in testloader:\n",
        "        inputs, labels = data\n",
        "        outputs = model(inputs)\n",
        "        _, prediction = torch.max(outputs, 1)\n",
        "        total += labels.shape[0]\n",
        "        score += (prediction==labels).sum().item()\n",
        "      print('Accuracy of Neural Network on the {} test images: {} %'.format(total, score/total * 100))\n",
        "  \n",
        "def save_model(model):\n",
        "  torch.save(model, 'cnn_mnist_torch.pt')\n",
        "    \n",
        "def load_model():\n",
        "  if os.path.isfile('cnn_mnist_torch.pt'):\n",
        "    model = torch.load('cnn_mnist_torch.pt')\n",
        "    return model\n",
        "  else:\n",
        "    print(\"Model not found.\")\n",
        "    return None\n",
        "model = LeNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ay9f2pBaremi",
        "colab_type": "code",
        "outputId": "6b1d4ff5-9055-4e62-fa3d-3b0a6a4d2414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id': downloaded.get('id')})  \n",
        "downloaded.GetContentFile('model.h5')\n",
        "model = torch.load('model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotDownloadableError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotDownloadableError\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-5904d788abb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdownloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mGetContentFile\u001b[0;34m(self, filename, mimetype, remove_bom)\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_bom\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchContent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mFetchContent\u001b[0;34m(self, mimetype, remove_bom)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       raise FileNotDownloadableError(\n\u001b[0;32m--> 265\u001b[0;31m         'No downloadLink/exportLinks for mimetype found in metadata')\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmimetype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'text/plain'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotDownloadableError\u001b[0m: No downloadLink/exportLinks for mimetype found in metadata"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xK5u7oI6oNoB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model = load_model()\n",
        "# if model == None:\n",
        "#   model = LeNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uytkXlocosLM",
        "colab_type": "code",
        "outputId": "5590970e-e8af-4a59-94c0-1622c707f217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.train(epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "usYHNx-9s1-J",
        "colab_type": "code",
        "outputId": "dbcefad6-1f9f-4a6d-aca9-26c8204f76bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.query()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Neural Network on the 10000 test images: 98.35000000000001 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "94KzuYwRk7N4",
        "colab_type": "code",
        "outputId": "d995731e-890a-47af-8760-ea89cbed0f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "torch.save(model, 'model.h5')\n",
        "# 2. Create & upload a file text file.\n",
        "uploaded = drive.CreateFile({'title': 'model.h5'})\n",
        "uploaded.SetContentFile('model.h5')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "# 3. Load a file by ID and print its contents.\n",
        "downloaded = drive.CreateFile({'id': uploaded.get('id')})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1fNNLsNDDDR3AVFoTcPRP4X9hptseFSvI\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}